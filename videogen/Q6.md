On a vu qu'il est possible de générer une playlist au format ffmpeg depuis
un modèle videogen, cependant passer par le développement d'un métamodèle Playlist permet de séparer la problèmatique de sélection de videos (aléatoire
pour "Alternative" et "Optional") de la problématique de génération textuelle
sous différents formats (ffmpeg, m3u, ...).
On attendait du développement du métamodèle Playlist la possiblité
de pouvoir rapidement exploiter les informations contenues dans
videogen pour faire des playlists, en ayant tous les "outils" générés
par ce métamodèle (classes PlaylstImpl, MediaImpl, etc).

Or, on découvre finalement que si l'on a conçu à partir d'un cahier
des charges (par exemple celui pour les fichiers ffmpeg) un
métamodèle Playlist et que l'on veut aussi produire des fichiers de
playlist M3U Extended, il faut pour cela non seulement modifier le
métamodèle (Ecore) de playlist pour  rajouter des attributs, mais
également le programme de transmformation de Model to Model et celui
de Model to Text.

Recommandation sur l’utilisation d’un métamodèle intermédiaire, de
transformations model-to-model, et de transformations model-to-text :
il est pratique de passer par l'utilisation de métamodèle intermédiaire,
qui implique la transformation model-to-model et model-to-text, lorsqu'entre
le domaine du métamodèle de départ et celui d'arrivée on a suffisament
de différences. Dans le métamodèle intermédiaire, lors de sa conception,
il faudrait extraire toutes les données qui sont présentes dans le métamodèle
de départ (ici celui de videogen), et éliminer les informations dont on sait
qu'elles ne sont pas pertinentes pour le métamodèle playlist.
